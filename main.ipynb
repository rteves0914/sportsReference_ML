{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull in dependencies needed from sportsreference api\n",
    "from sportsreference.mlb.teams import Teams\n",
    "from sportsreference.mlb.teams import Roster\n",
    "from sportsreference.mlb.roster import Player\n",
    "\n",
    "# pull in all other dependencies needed\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create a list of player ids:\n",
    "# set up an empty array that we will append to\n",
    "player_list = []\n",
    "\n",
    "# 1) create a loop to go through years\n",
    "for year in range(1876,2020):\n",
    "\n",
    "# 2) create a loop to go through teams and pull out the player names and their ids\n",
    "    for team in Teams(year):\n",
    "        player_data = Roster(team.abbreviation, year = year, slim=True).players\n",
    "        player_list.append(player_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dictionay of arrays to an array of arrays using list comprehension\n",
    "info = [list(x.keys()) for x in player_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the list using itertools\n",
    "merged = list(itertools.chain(*info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas data frame that will show all of the player ids\n",
    "df = pd.DataFrame(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .unique() on the df to clear out any duplicate players\n",
    "unique_player_id = df[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 19494\n",
      "1 19494\n",
      "2 19494\n",
      "3 19494\n",
      "4 19494\n",
      "5 19494\n",
      "6 19494\n",
      "7 19494\n",
      "8 19494\n",
      "9 19494\n",
      "10 19494\n",
      "11 19494\n",
      "12 19494\n",
      "13 19494\n",
      "14 19494\n",
      "15 19494\n",
      "16 19494\n",
      "17 19494\n",
      "18 19494\n",
      "19 19494\n",
      "20 19494\n",
      "21 19494\n",
      "22 19494\n",
      "23 19494\n",
      "skip\n",
      "25 19494\n",
      "26 19494\n",
      "27 19494\n",
      "28 19494\n",
      "29 19494\n",
      "skip\n",
      "31 19494\n",
      "32 19494\n",
      "33 19494\n",
      "34 19494\n",
      "35 19494\n",
      "36 19494\n",
      "37 19494\n",
      "38 19494\n",
      "39 19494\n",
      "40 19494\n",
      "41 19494\n",
      "42 19494\n",
      "43 19494\n",
      "44 19494\n",
      "45 19494\n",
      "46 19494\n",
      "47 19494\n",
      "48 19494\n",
      "49 19494\n",
      "50 19494\n",
      "51 19494\n",
      "52 19494\n",
      "53 19494\n",
      "54 19494\n",
      "55 19494\n",
      "56 19494\n",
      "57 19494\n",
      "58 19494\n",
      "59 19494\n",
      "60 19494\n",
      "61 19494\n",
      "skip\n",
      "63 19494\n",
      "64 19494\n",
      "skip\n",
      "66 19494\n",
      "67 19494\n",
      "68 19494\n",
      "69 19494\n",
      "70 19494\n",
      "71 19494\n",
      "skip\n",
      "73 19494\n",
      "74 19494\n",
      "skip\n",
      "skip\n",
      "skip\n",
      "78 19494\n",
      "79 19494\n",
      "skip\n",
      "81 19494\n",
      "82 19494\n",
      "skip\n",
      "84 19494\n",
      "85 19494\n",
      "skip\n",
      "87 19494\n",
      "skip\n",
      "89 19494\n",
      "90 19494\n",
      "91 19494\n",
      "92 19494\n",
      "skip\n",
      "94 19494\n",
      "95 19494\n",
      "skip\n",
      "skip\n",
      "98 19494\n",
      "skip\n",
      "100 19494\n",
      "skip\n",
      "skip\n",
      "skip\n",
      "104 19494\n",
      "105 19494\n",
      "106 19494\n",
      "107 19494\n",
      "108 19494\n",
      "109 19494\n",
      "110 19494\n",
      "111 19494\n",
      "112 19494\n",
      "113 19494\n",
      "114 19494\n",
      "115 19494\n",
      "116 19494\n",
      "117 19494\n",
      "118 19494\n",
      "119 19494\n",
      "120 19494\n",
      "121 19494\n",
      "122 19494\n",
      "123 19494\n",
      "124 19494\n",
      "125 19494\n",
      "skip\n",
      "127 19494\n",
      "skip\n",
      "129 19494\n",
      "skip\n",
      "131 19494\n",
      "skip\n",
      "skip\n",
      "134 19494\n",
      "skip\n",
      "136 19494\n",
      "skip\n",
      "138 19494\n",
      "139 19494\n",
      "140 19494\n",
      "141 19494\n",
      "142 19494\n",
      "143 19494\n",
      "144 19494\n",
      "145 19494\n",
      "skip\n",
      "147 19494\n",
      "148 19494\n",
      "149 19494\n",
      "150 19494\n",
      "151 19494\n",
      "152 19494\n",
      "153 19494\n",
      "154 19494\n",
      "155 19494\n",
      "156 19494\n",
      "157 19494\n",
      "158 19494\n",
      "skip\n",
      "160 19494\n",
      "161 19494\n",
      "162 19494\n",
      "skip\n",
      "164 19494\n",
      "165 19494\n",
      "166 19494\n",
      "167 19494\n",
      "skip\n",
      "169 19494\n",
      "170 19494\n",
      "skip\n",
      "skip\n",
      "173 19494\n",
      "174 19494\n",
      "skip\n",
      "skip\n",
      "177 19494\n",
      "178 19494\n",
      "179 19494\n",
      "180 19494\n",
      "181 19494\n",
      "182 19494\n",
      "skip\n",
      "184 19494\n",
      "185 19494\n",
      "186 19494\n",
      "187 19494\n",
      "188 19494\n",
      "189 19494\n",
      "190 19494\n",
      "191 19494\n",
      "192 19494\n",
      "193 19494\n",
      "194 19494\n",
      "195 19494\n",
      "196 19494\n",
      "197 19494\n",
      "198 19494\n",
      "skip\n",
      "200 19494\n",
      "201 19494\n",
      "202 19494\n",
      "203 19494\n",
      "204 19494\n",
      "205 19494\n",
      "206 19494\n",
      "207 19494\n",
      "208 19494\n",
      "209 19494\n",
      "210 19494\n",
      "211 19494\n",
      "212 19494\n",
      "213 19494\n",
      "skip\n",
      "215 19494\n",
      "216 19494\n",
      "skip\n",
      "218 19494\n",
      "219 19494\n",
      "220 19494\n",
      "221 19494\n",
      "222 19494\n",
      "223 19494\n",
      "224 19494\n",
      "skip\n",
      "skip\n",
      "227 19494\n",
      "228 19494\n",
      "229 19494\n",
      "230 19494\n",
      "231 19494\n",
      "232 19494\n",
      "skip\n",
      "234 19494\n",
      "235 19494\n",
      "236 19494\n",
      "237 19494\n",
      "238 19494\n",
      "skip\n",
      "240 19494\n",
      "241 19494\n",
      "242 19494\n",
      "243 19494\n",
      "244 19494\n",
      "skip\n",
      "246 19494\n",
      "247 19494\n",
      "248 19494\n",
      "249 19494\n",
      "skip\n",
      "251 19494\n",
      "252 19494\n",
      "253 19494\n",
      "skip\n",
      "255 19494\n",
      "skip\n",
      "257 19494\n",
      "258 19494\n",
      "259 19494\n",
      "260 19494\n",
      "261 19494\n",
      "262 19494\n",
      "263 19494\n",
      "264 19494\n",
      "skip\n",
      "266 19494\n",
      "267 19494\n",
      "268 19494\n",
      "269 19494\n",
      "270 19494\n",
      "271 19494\n",
      "272 19494\n",
      "273 19494\n",
      "274 19494\n",
      "275 19494\n",
      "276 19494\n",
      "277 19494\n",
      "278 19494\n",
      "279 19494\n",
      "280 19494\n",
      "281 19494\n",
      "282 19494\n",
      "skip\n",
      "284 19494\n",
      "285 19494\n",
      "286 19494\n",
      "skip\n"
     ]
    }
   ],
   "source": [
    "# to create a list of data frames for each player's stats:\n",
    "# set up an empty array that we will append to\n",
    "player_df_list = []\n",
    "\n",
    "# create a loop that will find each players' id and create a data frame of relevant statistics\n",
    "for index, player_id in enumerate(unique_player_id):\n",
    "    try:\n",
    "        player_df = Player(player_id).dataframe[[\"player_id\", \"name\", \"at_bats\", \"runs\", \"hits\", \"runs_batted_in\", \"bases_on_balls\", \"batting_average\", \"doubles\", \"triples\", \"home_runs\", \"stolen_bases\"]]\n",
    "        player_df_list.append(player_df)\n",
    "        print(index, len(unique_player_id))\n",
    "    except:\n",
    "        print(\"skip\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .loc function in pandas to just obtain the career stats for every player\n",
    "career_df_list = []\n",
    "for df in player_df_list:\n",
    "    career_df_list.append(df.loc[\"Career\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use concat to re-write the list of data frames as a single data frame\n",
    "clean_df = pd.concat(career_df_list)\n",
    "\n",
    "# and drop the duplicates of names using either 'player_id' or 'name'\n",
    "mlb_history_df = clean_df.drop_duplicates(subset=['player_id'])\n",
    "mlb_history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the hall of fame csv\n",
    "hall_of_fame_df = pd.read_csv('Resources/Hall_of_Fame_List.csv')\n",
    "hall_of_fame_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the csv file to show only the names of the hall of famers and status\n",
    "hall_of_fame_df = hall_of_fame_df.dropna()\n",
    "hof_df = hall_of_fame_df.rename(columns={\"Name\":\"name\", \"Primary position\": \"position\"})\n",
    "hof_cleaned = hof_df[[\"name\", \"position\"]]\n",
    "hof_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the no_duplicates_df with hof_cleaned to show career stats and hall of fame status\n",
    "merge_df = mlb_history_df.merge(hof_cleaned, on='name', how='outer')\n",
    "final_df = merge_df.fillna('no').rename(columns={\"position\": \"hall_of_fame\"})\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as a csv to Resources folder\n",
    "final_df.to_csv('Resources/player_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
